{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Information Extraction & Summarization\n",
        "\n",
        "**Objective:** Extract meaningful entities or features from text and generate document summaries.\n"
      ],
      "metadata": {
        "id": "Fm05dWqZ8qqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset loading"
      ],
      "metadata": {
        "id": "FzILr7bQ82uf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "d5Wh1UiN4v8z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "bd832a4a-e085-45de-b503-f63281d92834"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  SVD Perspectives for Augmenting DeepONet Flexi...   \n",
              "1  Towards robust audio spoofing detection: a det...   \n",
              "2            Guided Random Forest in the RRF Package   \n",
              "3  Best Arm Identification in Generalized Linear ...   \n",
              "4  Conditional Affordance Learning for Driving in...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0    Deep operator networks (DeepONets) are power...   \n",
              "1    Automatic speaker verification, like every o...   \n",
              "2    Random Forest (RF) is a powerful supervised ...   \n",
              "3    Motivated by drug design, we consider the be...   \n",
              "4    Most existing approaches to autonomous drivi...   \n",
              "\n",
              "                                  processed_abstract  \n",
              "0  deep operator network deeponet powerful archit...  \n",
              "1  automatic speaker verification like every biom...  \n",
              "2  random forest rf powerful supervise learner po...  \n",
              "3  motivated drug design consider good arm identi...  \n",
              "4  exist approach autonomous driving fall one two...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-923b1f0a-824d-4a87-bc24-95f4741a787b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>processed_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SVD Perspectives for Augmenting DeepONet Flexi...</td>\n",
              "      <td>Deep operator networks (DeepONets) are power...</td>\n",
              "      <td>deep operator network deeponet powerful archit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Towards robust audio spoofing detection: a det...</td>\n",
              "      <td>Automatic speaker verification, like every o...</td>\n",
              "      <td>automatic speaker verification like every biom...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Guided Random Forest in the RRF Package</td>\n",
              "      <td>Random Forest (RF) is a powerful supervised ...</td>\n",
              "      <td>random forest rf powerful supervise learner po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Best Arm Identification in Generalized Linear ...</td>\n",
              "      <td>Motivated by drug design, we consider the be...</td>\n",
              "      <td>motivated drug design consider good arm identi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Conditional Affordance Learning for Driving in...</td>\n",
              "      <td>Most existing approaches to autonomous drivi...</td>\n",
              "      <td>exist approach autonomous driving fall one two...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-923b1f0a-824d-4a87-bc24-95f4741a787b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-923b1f0a-824d-4a87-bc24-95f4741a787b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-923b1f0a-824d-4a87-bc24-95f4741a787b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-016a683d-e28c-41ee-9fde-42bc3184de36\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-016a683d-e28c-41ee-9fde-42bc3184de36')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-016a683d-e28c-41ee-9fde-42bc3184de36 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(sample_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Towards robust audio spoofing detection: a detailed comparison of\\n  traditional and learned features\",\n          \"Conditional Affordance Learning for Driving in Urban Environments\",\n          \"Guided Random Forest in the RRF Package\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"  Automatic speaker verification, like every other biometric system, is\\nvulnerable to spoofing attacks. Using only a few minutes of recorded voice of a\\ngenuine client of a speaker verification system, attackers can develop a\\nvariety of spoofing attacks that might trick such systems. Detecting these\\nattacks using the audio cues present in the recordings is an important\\nchallenge. Most existing spoofing detection systems depend on knowing the used\\nspoofing technique. With this research, we aim at overcoming this limitation,\\nby examining robust audio features, both traditional and those learned through\\nan autoencoder, that are generalizable over different types of replay spoofing.\\nFurthermore, we provide a detailed account of all the steps necessary in\\nsetting up state-of-the-art audio feature detection, pre-, and postprocessing,\\nsuch that the (non-audio expert) machine learning researcher can implement such\\nsystems. Finally, we evaluate the performance of our robust replay speaker\\ndetection system with a wide variety and different combinations of both\\nextracted and machine learned audio features on the `out in the wild' ASVspoof\\n2017 dataset. This dataset contains a variety of new spoofing configurations.\\nSince our focus is on examining which features will ensure robustness, we base\\nour system on a traditional Gaussian Mixture Model-Universal Background Model.\\nWe then systematically investigate the relative contribution of each feature\\nset. The fused models, based on both the known audio features and the machine\\nlearned features respectively, have a comparable performance with an Equal\\nError Rate (EER) of 12. The final best performing model, which obtains an EER\\nof 10.8, is a hybrid model that contains both known and machine learned\\nfeatures, thus revealing the importance of incorporating both types of features\\nwhen developing a robust spoofing prediction model.\\n\",\n          \"  Most existing approaches to autonomous driving fall into one of two\\ncategories: modular pipelines, that build an extensive model of the\\nenvironment, and imitation learning approaches, that map images directly to\\ncontrol outputs. A recently proposed third paradigm, direct perception, aims to\\ncombine the advantages of both by using a neural network to learn appropriate\\nlow-dimensional intermediate representations. However, existing direct\\nperception approaches are restricted to simple highway situations, lacking the\\nability to navigate intersections, stop at traffic lights or respect speed\\nlimits. In this work, we propose a direct perception approach which maps video\\ninput to intermediate representations suitable for autonomous navigation in\\ncomplex urban environments given high-level directional inputs. Compared to\\nstate-of-the-art reinforcement and conditional imitation learning approaches,\\nwe achieve an improvement of up to 68 % in goal-directed navigation on the\\nchallenging CARLA simulation benchmark. In addition, our approach is the first\\nto handle traffic lights and speed signs by using image-level labels only, as\\nwell as smooth car-following, resulting in a significant reduction of traffic\\naccidents in simulation.\\n\",\n          \"  Random Forest (RF) is a powerful supervised learner and has been popularly\\nused in many applications such as bioinformatics.\\n  In this work we propose the guided random forest (GRF) for feature selection.\\nSimilar to a feature selection method called guided regularized random forest\\n(GRRF), GRF is built using the importance scores from an ordinary RF. However,\\nthe trees in GRRF are built sequentially, are highly correlated and do not\\nallow for parallel computing, while the trees in GRF are built independently\\nand can be implemented in parallel. Experiments on 10 high-dimensional gene\\ndata sets show that, with a fixed parameter value (without tuning the\\nparameter), RF applied to features selected by GRF outperforms RF applied to\\nall features on 9 data sets and 7 of them have significant differences at the\\n0.05 level. Therefore, both accuracy and interpretability are significantly\\nimproved. GRF selects more features than GRRF, however, leads to better\\nclassification accuracy. Note in this work the guided random forest is guided\\nby the importance scores from an ordinary random forest, however, it can also\\nbe guided by other methods such as human insights (by specifying $\\\\lambda_i$).\\nGRF can be used in \\\"RRF\\\" v1.4 (and later versions), a package that also\\nincludes the regularized random forest methods.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"automatic speaker verification like every biometric system vulnerable spoofing attack use minute record voice genuine client speaker verification system attacker develop variety spoofing attack might trick system detect attack use audio cue present recording important challenge exist spoof detection system depend know use spoof technique research aim overcome limitation examine robust audio feature traditional learn autoencoder generalizable different type replay spoof furthermore provide detailed account step necessary set state of the art audio feature detection pre- postprocessing non audio expert machine learn researcher implement system finally evaluate performance robust replay speaker detection system wide variety different combination extract machine learn audio feature wild asvspoof 2017 dataset dataset contain variety new spoofing configuration since focus examine feature ensure robustness base system traditional gaussian mixture model universal background model systematically investigate relative contribution feature set fuse model base know audio feature machine learn feature respectively comparable performance equal error rate eer final good performing model obtain eer hybrid model contain know machine learn feature thus reveal importance incorporate type feature develop robust spoof prediction model\",\n          \"exist approach autonomous driving fall one two category modular pipeline build extensive model environment imitation learn approach map image directly control output recently propose third paradigm direct perception aim combine advantage use neural network learn appropriate low dimensional intermediate representation however exist direct perception approach restrict simple highway situation lack ability navigate intersection stop traffic light respect speed limit work propose direct perception approach map video input intermediate representation suitable autonomous navigation complex urban environment give high level directional input compare state of the art reinforcement conditional imitation learning approach achieve improvement 68 goal direct navigation challenge carla simulation benchmark addition approach first handle traffic light speed sign use image level label well smooth car follow result significant reduction traffic accident simulation\",\n          \"random forest rf powerful supervise learner popularly use many application bioinformatics work propose guide random forest grf feature selection similar feature selection method call guide regularize random forest grrf grf build use importance score ordinary rf however tree grrf build sequentially highly correlate allow parallel computing tree grf build independently implement parallel experiment 10 high dimensional gene datum set show fix parameter value without tune parameter rf applied feature select grf outperform rf applied feature 9 datum set 7 significant difference level therefore accuracy interpretability significantly improve grf select feature grrf however lead well classification accuracy note work guide random forest guide importance score ordinary random forest however also guide method human insight specify grf use rrf late version package also includes regularize random forest method\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "sample_df = pd.read_csv('sample_df.csv')\n",
        "display(sample_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entity & Information Extraction"
      ],
      "metadata": {
        "id": "koijmL1BFaTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy --quiet\n",
        "!python -m spacy download en_core_web_sm --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j00CYTIrFyW9",
        "outputId": "d8cad4ed-3e06-4b4a-9773-131ffc432537"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def regex_extraction(text):\n",
        "    \"\"\"\n",
        "    Extracts:\n",
        "    - Dates in formats like 2023-05-10, 05/10/2023, May 2023\n",
        "    - Numbers/metrics (including decimals)\n",
        "    - Email addresses\n",
        "    \"\"\"\n",
        "    # Date patterns\n",
        "    date_pattern = r\"\\b(?:\\d{4}-\\d{2}-\\d{2}|\\d{1,2}/\\d{1,2}/\\d{2,4}|\\b(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* \\d{4})\\b\"\n",
        "\n",
        "    # Numeric/metric patterns\n",
        "    number_pattern = r\"\\b\\d+(?:\\.\\d+)?\\b\"\n",
        "\n",
        "    # Email pattern\n",
        "    email_pattern = r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\"\n",
        "\n",
        "    dates = re.findall(date_pattern, text)\n",
        "    numbers = re.findall(number_pattern, text)\n",
        "    emails = re.findall(email_pattern, text)\n",
        "\n",
        "    return {\n",
        "        \"dates\": dates,\n",
        "        \"numbers\": numbers,\n",
        "        \"emails\": emails\n",
        "    }\n",
        "\n",
        "def spacy_ner_extraction(texts, batch_size=20):\n",
        "    \"\"\"\n",
        "    Runs spaCy NER on a list of texts and returns entity label counts.\n",
        "    \"\"\"\n",
        "    entity_counter = Counter()\n",
        "    entity_examples = {}\n",
        "\n",
        "    for doc in nlp.pipe(texts, batch_size=batch_size):\n",
        "        for ent in doc.ents:\n",
        "            entity_counter[ent.label_] += 1\n",
        "            # Store a small sample of examples per entity type\n",
        "            if ent.label_ not in entity_examples:\n",
        "                entity_examples[ent.label_] = set()\n",
        "            if len(entity_examples[ent.label_]) < 5:\n",
        "                entity_examples[ent.label_].add(ent.text)\n",
        "\n",
        "    # Convert examples sets to lists\n",
        "    entity_examples = {k: list(v) for k, v in entity_examples.items()}\n",
        "\n",
        "    return entity_counter, entity_examples"
      ],
      "metadata": {
        "id": "5fzJmRcDFdec"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = sample_df.sample(n=50, random_state=42)\n",
        "sample_texts = sample[\"processed_abstract\"].tolist()\n",
        "\n",
        "# Rule-based extraction on first sample text\n",
        "print(\"Rule-Based Extraction Example\")\n",
        "print(regex_extraction(sample_texts[0]))\n",
        "\n",
        "# NER extraction on all sample texts\n",
        "entity_counts, entity_samples = spacy_ner_extraction(sample_texts)\n",
        "print(\"\\n Entity Counts\")\n",
        "print(entity_counts)\n",
        "print(\"\\n Entity Examples\")\n",
        "print(entity_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZDAVG_KGCid",
        "outputId": "06b0b635-bd63-40cd-f29c-0de2d49e7567"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Rule-Based Extraction Example\n",
            "{'dates': [], 'numbers': ['1', '2', '3'], 'emails': []}\n",
            "\n",
            "üîπ Entity Counts\n",
            "Counter({'CARDINAL': 77, 'ORG': 24, 'ORDINAL': 19, 'DATE': 17, 'PERSON': 11, 'GPE': 4, 'NORP': 4, 'TIME': 1, 'PERCENT': 1})\n",
            "\n",
            "üîπ Entity Examples\n",
            "{'DATE': ['vector', 'come year', 'come decade', 'covid-19', 'today'], 'CARDINAL': ['3', '2', '1', 'three', 'one'], 'ORDINAL': ['second', 'third', 'first'], 'ORG': ['cnn', 'linear', 'mt simon sandstone', 'algorithm estimate comfort level function', 'modifie'], 'TIME': ['overnight'], 'GPE': ['automaton', 'santa barbara county', 'california', 'cleveland'], 'PERSON': ['ipn achieve state', 'gan generate', 'max', 'gan fbgan', 'baye algorithm'], 'PERCENT': ['2d 3d'], 'NORP': ['aviris', 'boolean', 'pfaffian', 'english']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarization"
      ],
      "metadata": {
        "id": "_AF_iiV_HGmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 1. Load pre-trained BART summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "def abstractive_summarization(texts, max_length=130, min_length=50):\n",
        "    \"\"\"\n",
        "    Summarizes a list of texts using BART.\n",
        "    Parameters:\n",
        "        texts (list[str]): List of documents to summarize\n",
        "        max_length (int): Maximum length of generated summary tokens\n",
        "        min_length (int): Minimum length of generated summary tokens\n",
        "    Returns:\n",
        "        list[str]: List of summaries\n",
        "    \"\"\"\n",
        "    summaries = []\n",
        "    for text in texts:\n",
        "        # Ensure text isn't too long for the model\n",
        "        input_text = text[:1024]  # BART handles ~1024 tokens\n",
        "        summary = summarizer(input_text, max_length=max_length, min_length=min_length, do_sample=False)\n",
        "        summaries.append(summary[0]['summary_text'])\n",
        "    return summaries\n",
        "\n",
        "\n",
        "sample_texts = sample_df[\"abstract\"].sample(n=3, random_state=42).tolist()\n",
        "\n",
        "summaries = abstractive_summarization(sample_texts)\n",
        "\n",
        "for i, (orig, summ) in enumerate(zip(sample_texts, summaries), start=1):\n",
        "    print(f\"\\nüîπ Example {i}\")\n",
        "    print(f\"Original Text ({len(orig)} characters):\\n\", orig[:500], \"...\")\n",
        "    print(f\"\\nGenerated Summary ({len(summ)} characters):\\n\", summ)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10_huqtqGouz",
        "outputId": "f5da1dec-907c-4f2e-d124-c7e7fa486b7d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîπ Example 1\n",
            "Original Text (1496 characters):\n",
            "   Tree-based machine learning models such as random forests, decision trees,\n",
            "and gradient boosted trees are the most popular non-linear predictive models\n",
            "used in practice today, yet comparatively little attention has been paid to\n",
            "explaining their predictions. Here we significantly improve the\n",
            "interpretability of tree-based models through three main contributions: 1) The\n",
            "first polynomial time algorithm to compute optimal explanations based on game\n",
            "theory. 2) A new type of explanation that directl ...\n",
            "\n",
            "Generated Summary (376 characters):\n",
            " Tree-based machine learning models are the most popular non-linear predictive models used in practice today. Here we significantly improve theinterpretability of tree-based models through three main contributions. We show how combining many high-quality local explanations allows us to represent global model structure while retaining local faithfulness to the original model.\n",
            "\n",
            "üîπ Example 2\n",
            "Original Text (1036 characters):\n",
            "   Identifying sleep problem severity from overnight polysomnography (PSG)\n",
            "recordings plays an important role in diagnosing and treating sleep disorders\n",
            "such as the Obstructive Sleep Apnea (OSA). This analysis traditionally is done\n",
            "by specialists manually through visual inspections, which can be tedious,\n",
            "time-consuming, and is prone to subjective errors. One of the solutions is to\n",
            "use Convolutional Neural Networks (CNN) where the convolutional and pooling\n",
            "layers behave as feature extractors and s ...\n",
            "\n",
            "Generated Summary (349 characters):\n",
            " Identifying sleep problem severity from overnight polysomnography (PSG) records plays an important role in diagnosing and treating sleep disorders. This analysis traditionally is doneby specialists manually through visual inspections, which can be tedious and prone to subjective errors. One of the solutions is to use Convolutional Neural Networks.\n",
            "\n",
            "üîπ Example 3\n",
            "Original Text (795 characters):\n",
            "   We present a method to learn automaton models that are more robust to input\n",
            "modifications. It iteratively aligns sequences to a learned model, modifies the\n",
            "sequences to their aligned versions, and re-learns the model. Automaton\n",
            "learning algorithms are typically very good at modeling the frequent behavior\n",
            "of a software system. Our solution can be used to also learn the behavior\n",
            "present in infrequent sequences, as these will be aligned to the frequent ones\n",
            "represented by the model. We apply our  ...\n",
            "\n",
            "Generated Summary (337 characters):\n",
            " We present a method to learn automaton models that are more robust to input. It iteratively aligns sequences to a learned model, modifies thesequences to their aligned versions, and re-learns the model. In experiments, we demonstrate thatour algorithm learns models that can handle noise such as added and removed symbols from sequences.\n"
          ]
        }
      ]
    }
  ]
}